{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bb314-3035-4ecd-ae4e-3475abffcb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b5ee7-c53d-4348-8c4b-eacb2655fedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#나눔폰트 설"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e070a9e-5218-4ca4-94e2-c756fca554bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt-get update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08d83a-7929-4d44-b5aa-4f21a10486e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo apt-get install -y fonts-nanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434f9a7a-d117-4db3-8304-e141df9a535b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "설정된 폰트: NanumBarunGothic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.ticker as ticker\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.ERROR)\n",
    "\n",
    "fontpath = \"/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf\"\n",
    "fontprop = fm.FontProperties(fname=fontpath, size=12)\n",
    "plt.rcParams[\"font.family\"] = fontprop.get_name()\n",
    "\n",
    "print(f\"설정된 폰트: {fontprop.get_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db3bb65-3df8-48da-96a1-fda617a9b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b95a1e-5387-4c41-841b-d63e8b11d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "972982d4-1b94-4f01-9c46-574156c9a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/s2s_translation\n"
     ]
    }
   ],
   "source": [
    "%cd ~/work/s2s_translation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26c8f6f7-6e30-42e3-9c39-f78ab40b0b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korean-english-park.train.en\n",
      "korean-english-park.train.ko\n",
      "total 33972\n",
      "-rw-r--r-- 1 jovyan users   113461 Sep  3 16:04 korean-english-park.dev.tar.gz\n",
      "-rw-r--r-- 1 jovyan users   229831 Sep  3 16:04 korean-english-park.test.tar.gz\n",
      "-rw-r--r-- 1 jovyan users 11982221 Jul 12  2014 korean-english-park.train.en\n",
      "-rw-r--r-- 1 jovyan users 13730884 Jul 12  2014 korean-english-park.train.ko\n",
      "-rw-r--r-- 1 jovyan users  8718893 Sep  3 16:04 korean-english-park.train.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# 1. tar 명령어로 압축을 풉니다.\n",
    "# 현재 폴더에 있는 파일을 지정하므로, 앞의 경로 부분은 모두 제거합니다.\n",
    "!tar -xzvf korean-english-park.train.tar.gz\n",
    "\n",
    "# 2. 압축 해제 후 파일 목록을 확인합니다.\n",
    "# korean-english-park.train.tsv 파일이 새로 생성된 것을 볼 수 있습니다.\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16167dc4-e7d1-46c1-bc71-8fb0eb7c5b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "596baae0-8536-45dd-b3c5-a53ee4771cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1단계: 데이터 로드 시작 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_518/13032387.py:22: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 데이터셋(train, dev, test) 준비 완료!\n",
      "\n",
      "--- [확인] 로드된 Train 데이터 샘플 (상위 3개) ---\n",
      "                                                                                       korean  \\\n",
      "0                                        모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다.   \n",
      "1                                                                  그러나 이것은 또한 책상도 필요로 하지 않는다.   \n",
      "2  79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분이든 그 움직임에따라 커서의 움직임을 조절하는 회전 운동 센서를 사용하고 있다.   \n",
      "\n",
      "                                                                                                                     english  \n",
      "0  so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.  \n",
      "1                                                                    Like all optical mice, But it also doesn't need a desk.  \n",
      "2              uses gyroscopic sensors to control the cursor movement as you move your wrist, arm, whatever through the air.  \n",
      "\n",
      "Train 데이터 개수: 94122\n",
      "Dev 데이터 개수: 999\n",
      "Test 데이터 개수: 1999\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# ## 1단계: 데이터 로드 및 통합\n",
    "# # 로컬에 저장된 tar.gz 파일들의 압축을 풀고,\n",
    "# # 분리된 한국어(.ko), 영어(.en) 파일을 읽어 하나의 DataFrame으로 만듭니다.\n",
    "# ======================================================================\n",
    "print(\"--- 1단계: 데이터 로드 시작 ---\")\n",
    "\n",
    "# 데이터 파일 목록을 딕셔너리로 정의합니다.\n",
    "file_list = {\n",
    "    'train': 'korean-english-park.train.tar.gz',\n",
    "    'dev': 'korean-english-park.dev.tar.gz',\n",
    "    'test': 'korean-english-park.test.tar.gz'\n",
    "}\n",
    "\n",
    "# 생성된 데이터프레임을 저장할 딕셔너리를 초기화합니다.\n",
    "data_frames = {}\n",
    "\n",
    "# 각 파일을 순회하며 압축을 풀고 DataFrame을 생성합니다.\n",
    "for name, file_name in file_list.items():\n",
    "    # 1. tar.gz 압축 해제\n",
    "    with tarfile.open(file_name, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "        \n",
    "    # 2. 압축 해제된 파일들의 경로를 정의합니다.\n",
    "    base_name = file_name.replace(\".tar.gz\", \"\")\n",
    "    ko_file_path = f\"{base_name}.ko\"\n",
    "    en_file_path = f\"{base_name}.en\"\n",
    "    \n",
    "    # 3. 한국어 파일을 한 줄씩 읽어 리스트에 저장합니다.\n",
    "    with open(ko_file_path, 'r', encoding='utf-8') as f:\n",
    "        ko_lines = [line.strip() for line in f]\n",
    "    \n",
    "    # 4. 영어 파일을 한 줄씩 읽어 리스트에 저장합니다.\n",
    "    with open(en_file_path, 'r', encoding='utf-8') as f:\n",
    "        en_lines = [line.strip() for line in f]\n",
    "        \n",
    "    # 5. DataFrame 생성 (첫 줄은 파일명이므로 제외)\n",
    "    df = pd.DataFrame({\n",
    "        'korean': ko_lines[1:],\n",
    "        'english': en_lines[1:]\n",
    "    })\n",
    "    \n",
    "    # 6. 생성된 DataFrame을 딕셔너리에 저장합니다.\n",
    "    data_frames[name] = df\n",
    "\n",
    "# 각 데이터프레임을 사용하기 쉬운 변수에 할당합니다.\n",
    "train_df = data_frames['train']\n",
    "dev_df = data_frames['dev']\n",
    "test_df = data_frames['test']\n",
    "\n",
    "print(\" 모든 데이터셋(train, dev, test) 준비 완료!\")\n",
    "# --- [확인] 로드된 데이터 샘플 출력 ---\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(\"\\n--- [확인] 로드된 Train 데이터 샘플 (상위 3개) ---\")\n",
    "print(train_df.head(3))\n",
    "# --- [추가] 각 데이터셋의 개수 확인 ---\n",
    "print(f\"\\nTrain 데이터 개수: {len(train_df)}\")\n",
    "print(f\"Dev 데이터 개수: {len(dev_df)}\")\n",
    "print(f\"Test 데이터 개수: {len(test_df)}\")\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e4107-d5a9-4fc6-931a-9a0937e1397d",
   "metadata": {},
   "source": [
    "* 데이터가 .. 퀄이 좋지 않음\n",
    "* 우선 다음 작업으로 넘어가 보다... 한사이클 돌려보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2cb1e582-d88d-4b4b-a9e3-5ea5795d2764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2단계: 텍스트 전처리 함수 정의 및 테스트 ---\n",
      "\n",
      "--- [확인] 전처리 함수 적용 결과 ---\n",
      "원본 문장: 1,960만갤론 이상의 중유를 운반하던 손상된 유조선이 스페인 북서부 연안 130마일 해역에서 침몰하여, 스페인 당국이 어업이 주요 산업인 이 지역에서 해안선 보호를 위해 황급히 서두르고 있다.\n",
      "전처리 후: 1960만갤론 이상의 중유를 운반하던 손상된 유조선이 스페인 북서부 연안 130마일 해역에서 침몰하여, 스페인 당국이 어업이 주요 산업인 이 지역에서 해안선 보호를 위해 황급히 서두르고 있다 .\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# ## 2단계: 텍스트 전처리\n",
    "# # 문장을 모델이 학습하기 좋은 형태로 정제합니다.\n",
    "# # 숫자 내 쉼표(,) 제거, 문장 부호 분리 등을 수행합니다.\n",
    "# ======================================================================\n",
    "print(\"\\n--- 2단계: 텍스트 전처리 함수 정의 및 테스트 ---\")\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = str(sentence).lower().strip()\n",
    "    sentence = re.sub(r\"(\\d),(\\d)\", r\"\\1\\2\", sentence)\n",
    "    sentence = re.sub(r\"([?.!])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣0-9?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "# --- [확인] 전처리 함수 테스트 ---\n",
    "sample_idx = 100\n",
    "original_sentence = train_df['korean'][sample_idx]\n",
    "preprocessed_sentence = preprocess_sentence(original_sentence)\n",
    "print(\"\\n--- [확인] 전처리 함수 적용 결과 ---\")\n",
    "print(\"원본 문장:\", original_sentence)\n",
    "print(\"전처리 후:\", preprocessed_sentence)\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3a2ee-0ff0-4570-932f-ce4481f6cc46",
   "metadata": {},
   "source": [
    "* 전처리 수정 기록\n",
    "1차 숫자가 제거됨 > 2차 숫자사이 쉼표로 숫자가 분리됨 1 , 960 > 3차 숫자 사이 쉼표 별도 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41985f35-ddc9-44ce-bab0-dd052ab219a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3단계: SentencePiece 토크나이저 훈련 시작 ---\n",
      "✅ 토크나이저 훈련 완료!\n",
      "\n",
      "--- [확인] 생성된 한국어 단어 사전 (상위 10개 토큰) ---\n",
      "<pad>\t0\n",
      "<s>\t0\n",
      "</s>\t0\n",
      "<unk>\t0\n",
      "▁.\t-0\n",
      "▁이\t-1\n",
      "했다\t-2\n",
      "▁있\t-3\n",
      "에서\t-4\n",
      "▁대\t-5\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# ## 3단계: SentencePiece 토크나이저 훈련\n",
    "# # 훈련(Train) 데이터만을 사용하여 토크나이저 모델을 생성합니다.\n",
    "# ======================================================================\n",
    "print(\"\\n--- 3단계: SentencePiece 토크나이저 훈련 시작 ---\")\n",
    "\n",
    "with open(\"sp_train_ko.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in train_df['korean']:\n",
    "        f.write(preprocess_sentence(sentence) + '\\n')\n",
    "\n",
    "with open(\"sp_train_en.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for sentence in train_df['english']:\n",
    "        f.write(preprocess_sentence(sentence) + '\\n')\n",
    "\n",
    "vocab_size = 8000\n",
    "pad_id, bos_id, eos_id, unk_id = 0, 1, 2, 3\n",
    "\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f'--input=sp_train_ko.txt --model_prefix=korean_spm --vocab_size={vocab_size} '\n",
    "    f'--pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id} --model_type=bpe'\n",
    ")\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f'--input=sp_train_en.txt --model_prefix=english_spm --vocab_size={vocab_size} '\n",
    "    f'--pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} --unk_id={unk_id} --model_type=bpe'\n",
    ")\n",
    "\n",
    "print(\" 토크나이저 훈련 완료!\")\n",
    "# --- [수정] 생성된 단어 사전(.vocab) 내용을 파이썬으로 직접 읽어 확인 ---\n",
    "print(\"\\n--- [확인] 생성된 한국어 단어 사전 (상위 10개 토큰) ---\")\n",
    "with open('korean_spm.vocab', 'r', encoding='utf-8') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 10:\n",
    "            break\n",
    "        print(line.strip())\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00dbbaf8-b15f-4f7f-a187-7dd360781b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4단계: 전체 데이터셋 토큰화 및 후처리 시작 ---\n",
      "✅ 모든 데이터셋 토큰화 및 BOS/EOS 추가 완료!\n",
      "\n",
      "--- [확인] 토큰화 적용 결과 (첫 번째 샘플) ---\n",
      "Original Korean: 모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다.\n",
      "Tokenized Korean: [1, 439, 714, 6881, 6910, 1660, 5581, 172, 5, 714, 6881, 3452, 6851, 863, 6863, 5797, 1261, 6818, 73, 3452, 675, 1948, 546, 6826, 1043, 1324, 4, 2]\n",
      "Original English: so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.\n",
      "Tokenized English: [1, 377, 5, 5312, 5, 1316, 1498, 1162, 255, 5, 50, 124, 30, 237, 535, 7457, 3190, 339, 25, 566, 2625, 28, 869, 50, 124, 30, 237, 535, 7983, 7457, 25, 566, 12, 2]\n",
      "==================================================\n",
      "\n",
      "--- 길이 필터링 시작 ---\n",
      "길이 필터링 전: 94122 -> 후: 83804 (10,318개 제거)\n",
      "길이 필터링 전: 999 -> 후: 865 (134개 제거)\n",
      "길이 필터링 전: 1999 -> 후: 1732 (267개 제거)\n",
      "==================================================\n",
      "\n",
      "--- 최종 결과 확인 (필터링 후 Train 데이터 샘플) ---\n",
      "                                                                                              korean  \\\n",
      "0                                               모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하지 않는다.   \n",
      "1                                                                         그러나 이것은 또한 책상도 필요로 하지 않는다.   \n",
      "2         79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분이든 그 움직임에따라 커서의 움직임을 조절하는 회전 운동 센서를 사용하고 있다.   \n",
      "6  이 보고서에따르면, \"특히, 군사 작전에서 생사가 걸린 상황이 될 수도 있는 반응 속도와 시각 및 청각의 경계 상태를 유지시키기 위해 카페인이 사용될 수도 있다.\" 고 한다.   \n",
      "7                                                          \"결정적인 순간에 그들의 능력을 증가시켜 줄 그 무엇이 매우 중요합니다.\"   \n",
      "\n",
      "                                                                                                                                                                                         english  \\\n",
      "0                                                                      so a mention a few weeks ago about a rechargeable wireless optical mouse brought in another rechargeable, wireless mouse.   \n",
      "1                                                                                                                                        Like all optical mice, But it also doesn't need a desk.   \n",
      "2                                                                                  uses gyroscopic sensors to control the cursor movement as you move your wrist, arm, whatever through the air.   \n",
      "6  \"Specifically, it can be used in maintaining speed of reactions and visual and auditory vigilance, which in military operations could be a life or death situation,\" according to the report.   \n",
      "7                                                                                                           \"Something that will boost their capabilities at crucial moments is very important.\"   \n",
      "\n",
      "                                                                                                                                                                                                                                                         ko_tokens  \\\n",
      "0                                                                                                              [1, 439, 714, 6881, 6910, 1660, 5581, 172, 5, 714, 6881, 3452, 6851, 863, 6863, 5797, 1261, 6818, 73, 3452, 675, 1948, 546, 6826, 1043, 1324, 4, 2]   \n",
      "1                                                                                                                                                                                                [1, 205, 2748, 403, 863, 6863, 6851, 546, 6826, 1043, 1324, 4, 2]   \n",
      "2  [1, 195, 6949, 4, 6345, 408, 34, 5, 80, 4599, 5551, 714, 6881, 6910, 354, 521, 6895, 8, 540, 7109, 6847, 540, 6847, 12, 7071, 6817, 985, 1953, 6814, 7118, 12, 2970, 796, 1125, 6831, 6819, 6724, 65, 7164, 34, 119, 6853, 1605, 6561, 1218, 388, 37, 24, 4, 2]   \n",
      "6                                         [1, 5, 6647, 6847, 1808, 6847, 993, 191, 1700, 115, 511, 532, 7016, 2620, 371, 536, 71, 2138, 706, 6851, 6892, 5418, 491, 644, 7041, 6819, 4780, 840, 6832, 1362, 2549, 100, 4500, 499, 6461, 536, 24, 4, 21, 412, 4, 2]   \n",
      "7                                                                                                                                                                       [1, 474, 139, 2694, 6817, 2050, 5261, 768, 2186, 483, 12, 2323, 6814, 865, 834, 625, 4, 2]   \n",
      "\n",
      "                                                                                                                                                                                                         en_tokens  \n",
      "0                                                [1, 377, 5, 5312, 5, 1316, 1498, 1162, 255, 5, 50, 124, 30, 237, 535, 7457, 3190, 339, 25, 566, 2625, 28, 869, 50, 124, 30, 237, 535, 7983, 7457, 25, 566, 12, 2]  \n",
      "1                                                                                                                         [1, 452, 283, 3190, 339, 25, 169, 7983, 181, 86, 327, 2764, 4, 835, 5, 595, 7985, 12, 2]  \n",
      "2                                                       [1, 6339, 4674, 755, 7973, 119, 40, 3028, 321, 32, 1638, 9, 15, 518, 24, 3110, 97, 460, 1100, 1238, 1014, 136, 7983, 1113, 7983, 4980, 704, 9, 508, 12, 2]  \n",
      "6  [1, 7466, 7983, 86, 346, 56, 1106, 28, 4041, 31, 3295, 37, 2069, 270, 44, 715, 789, 44, 2581, 26, 510, 7242, 47, 451, 7983, 286, 28, 540, 2952, 470, 56, 5, 1142, 186, 839, 2284, 7983, 485, 32, 9, 400, 12, 2]  \n",
      "7                                                                                                                              [1, 2294, 85, 162, 3402, 243, 609, 182, 2985, 98, 5035, 7603, 81, 933, 1962, 12, 2]  \n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# ## 4단계: 전체 데이터셋 토큰화 및 후처리\n",
    "# # 훈련된 토크나이저를 사용하여 모든 데이터(train, dev, test)를\n",
    "# # 숫자 시퀀스로 변환하고, 후처리 작업을 수행합니다.\n",
    "# ======================================================================\n",
    "print(\"\\n--- 4단계: 전체 데이터셋 토큰화 및 후처리 시작 ---\")\n",
    "\n",
    "sp_ko = spm.SentencePieceProcessor(); sp_ko.load('korean_spm.model')\n",
    "sp_en = spm.SentencePieceProcessor(); sp_en.load('english_spm.model')\n",
    "\n",
    "for df in [train_df, dev_df, test_df]:\n",
    "    df['ko_tokens'] = df['korean'].apply(lambda x: [bos_id] + sp_ko.encode_as_ids(preprocess_sentence(x)) + [eos_id])\n",
    "    df['en_tokens'] = df['english'].apply(lambda x: [bos_id] + sp_en.encode_as_ids(preprocess_sentence(x)) + [eos_id])\n",
    "\n",
    "print(\" 모든 데이터셋 토큰화 및 BOS/EOS 추가 완료!\")\n",
    "\n",
    "# --- [확인] 토큰화 및 BOS/EOS 추가 결과 ---\n",
    "print(\"\\n--- [확인] 토큰화 적용 결과 (첫 번째 샘플) ---\")\n",
    "sample_row = train_df.iloc[0]\n",
    "print(\"Original Korean:\", sample_row['korean'])\n",
    "print(\"Tokenized Korean:\", sample_row['ko_tokens'])\n",
    "print(\"Original English:\", sample_row['english'])\n",
    "print(\"Tokenized English:\", sample_row['en_tokens'])\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 길이 필터링 시작 ---\")\n",
    "max_len = 50\n",
    "def filter_by_length(df, max_len):\n",
    "    before_len = len(df)\n",
    "    df = df[df.apply(lambda x: len(x['ko_tokens']) <= max_len and len(x['en_tokens']) <= max_len, axis=1)]\n",
    "    after_len = len(df)\n",
    "    print(f\"길이 필터링 전: {before_len} -> 후: {after_len} ({(before_len - after_len):,}개 제거)\")\n",
    "    return df\n",
    "\n",
    "train_df = filter_by_length(train_df, max_len)\n",
    "dev_df = filter_by_length(dev_df, max_len)\n",
    "test_df = filter_by_length(test_df, max_len)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n--- 최종 결과 확인 (필터링 후 Train 데이터 샘플) ---\")\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8b587d-6cd9-4453-9e56-898cfd493457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3af0b556-5498-43f1-8bc3-baa287048759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# ## 5단계: 라이브러리 임포트 및 기본 설정\n",
    "# ======================================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "661894c3-d471-45b7-9a62-06fb9a803237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DataLoader 준비 완료!\n",
      "Train 배치 개수: 655\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# ## 6단계: 데이터셋 및 데이터로더 생성\n",
    "# # pandas DataFrame을 PyTorch가 사용할 수 있는 Dataset과 DataLoader로 변환합니다.\n",
    "# # DataLoader는 학습 시 데이터를 배치(batch) 단위로 묶어주는 역할을 합니다.\n",
    "# ======================================================================\n",
    "\n",
    "# PyTorch Dataset 클래스 정의\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.src_sents = df['ko_tokens'].tolist()\n",
    "        self.trg_sents = df['en_tokens'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.src_sents[idx]), torch.tensor(self.trg_sents[idx])\n",
    "\n",
    "# collate_fn: DataLoader가 배치를 만들 때, 문장의 길이를 맞추기 위해 패딩(padding)을 적용합니다.\n",
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = [], []\n",
    "    for src_sample, trg_sample in batch:\n",
    "        src_batch.append(src_sample)\n",
    "        trg_batch.append(trg_sample)\n",
    "    \n",
    "    # pad_sequence를 사용하여 PAD_ID(0)로 길이를 맞춥니다.\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=pad_id)\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=pad_id)\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "# Dataset 인스턴스 생성\n",
    "train_dataset = TextDataset(train_df)\n",
    "dev_dataset = TextDataset(dev_df)\n",
    "test_dataset = TextDataset(test_df)\n",
    "\n",
    "# DataLoader 생성\n",
    "BATCH_SIZE = 128\n",
    "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "dev_iterator = DataLoader(dev_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "print(\"\\n DataLoader 준비 완료!\")\n",
    "print(f\"Train 배치 개수: {len(train_iterator)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f2912-0cde-488f-8595-f5a47dea7468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e99c154-55e5-4fed-b627-2d7332393b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.W1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: (batch_size, hidden_dim)\n",
    "        # encoder_outputs: (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  # (batch_size, src_len, hidden_dim)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # (batch_size, src_len, hidden_dim)\n",
    "\n",
    "        energy = torch.tanh(self.W1(encoder_outputs) + self.W2(hidden))  # (batch_size, src_len, hidden_dim)\n",
    "        attention = self.v(energy).squeeze(2)  # (batch_size, src_len)\n",
    "\n",
    "        return nn.functional.softmax(attention, dim=1)  # (batch_size, src_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed331cf8-5ef4-4ce6-9caf-9d5095c84973",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src : (src_len, batch_size)\n",
    "        embedded = self.embedding(src)  # embedded : (src_len, batch_size, emb_dim)\n",
    "        outputs, hidden = self.rnn(embedded)  # outputs : (src_len, batch_size, hidden_dim)\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4258f339-e16c-4678-898c-2bdff3af53d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        # Decoder RNN에는 embedding만 입력\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim)\n",
    "        # 출력층에는 hidden state와 attention value가 결합되어 입력\n",
    "        self.fc_out = nn.Linear(hidden_dim + hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        # input : (batch_size,)\n",
    "        # hidden : (batch_size, hidden_dim)\n",
    "        # encoder_outputs : (src_len, batch_size, hidden_dim)\n",
    "        input = input.unsqueeze(0)  # input : (1, batch_size)\n",
    "        embedded = self.embedding(input)  # embedded : (1, batch_size, emb_dim)\n",
    "\n",
    "        # attention distribution을 계산합니다. decoder의 이전 hidden state, s_{t-1}와 encoder의 H가 입력됩니다.\n",
    "        a = self.attention(hidden[-1], encoder_outputs)  # a : (batch_size, src_len)\n",
    "\n",
    "        # H에 가중치를 부여해 attention value(Context vector) 계산\n",
    "        a = a.unsqueeze(1)  # a : (batch_size, 1, src_len)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)  # encoder_outputs : (batch_size, src_len, hidden_dim)\n",
    "        context = torch.bmm(a, encoder_outputs)  # context : (batch_size, 1, hidden_dim)\n",
    "        context = context.permute(1, 0, 2)  # context : (1, batch_size, hidden_dim)\n",
    "\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "        # 출력층에서는 현재 hidden state와 context vector를 결합하여 예측값 생성\n",
    "        output = output.squeeze(0)  # output : (batch_size, hidden_dim)\n",
    "        context = context.squeeze(0)  # context : (batch_size, hidden_dim)\n",
    "        prediction = self.fc_out(torch.cat((output, context), dim=1))  # (batch_size, output_dim)\n",
    "\n",
    "        return prediction, hidden, a.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce7e63a9-2d02-449f-b670-0a035fe60611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg=None, max_len=30, bos_id = 1, eos_id=2):\n",
    "        # 학습 모드에서는 trg_len 사용, 추론 모드에서는 max_len까지 동적 생성\n",
    "        batch_size = src.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "\n",
    "        # 조기 종료를 위해 tensor가 아닌 리스트 사용\n",
    "        outputs = []\n",
    "\n",
    "        # 시각화를 위해 attention 저장\n",
    "        attentions = []\n",
    "\n",
    "        # 인코더를 통해 context 생성\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        if trg is not None:\n",
    "            for t in range(0, trg.shape[0]):\n",
    "                input = trg[t]\n",
    "                output, hidden, attention = self.decoder(input, hidden, encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "\n",
    "        else:\n",
    "\t\t    # inference에서는 target(정답)이 없기 때문에 sos_token을 생성해줍니다.\n",
    "            input = torch.full((batch_size,), bos_id, dtype=torch.long, device=self.device)\n",
    "            finished = torch.zeros(batch_size, dtype=torch.bool, device=self.device)\n",
    "\n",
    "            for t in range(max_len):\n",
    "                output, hidden, attention = self.decoder(input, hidden,  encoder_outputs)\n",
    "                outputs.append(output.unsqueeze(0))\n",
    "                attentions.append(attention.unsqueeze(0))\n",
    "                top1 = output.argmax(1)\n",
    "                input = top1\n",
    "\n",
    "                # 조기 종료 조건\n",
    "                finished |= (top1 == eos_id)\n",
    "                if finished.all():\n",
    "                    break\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=0)  # (trg_len, batch_size, output_dim)\n",
    "        attentions = torch.cat(attentions, dim=0)  # (trg_len, batch_size, src_len)\n",
    "\n",
    "        return outputs, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14672648-19d0-4207-8f4e-e4fc323541e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m input_dim = \u001b[38;5;28mlen\u001b[39m(\u001b[43mencoder_tokenizer\u001b[49m)\n\u001b[32m      4\u001b[39m output_dim = \u001b[38;5;28mlen\u001b[39m(decoder_tokenizer)\n\u001b[32m      5\u001b[39m emb_dim = \u001b[32m256\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'encoder_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_dim = len(encoder_tokenizer)\n",
    "output_dim = len(decoder_tokenizer)encoder_tokenizer\n",
    "emb_dim = 256\n",
    "hid_dim = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333b3f2-2680-46e0-a636-218b10e82190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3b8b4-ef88-4a9d-9564-e403c66e775c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce5ec63-468a-4124-a414-b0f637ccdfa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae3954-0a0d-4b39-9855-e4431c965a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992057d6-1489-472a-9102-404d86f13d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb553684-0971-4402-bb57-15d8dc1ea9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded8a1d-69fb-467d-b5de-45e85ac359f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
